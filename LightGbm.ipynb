{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPY2JetwVDrPzHNxu7gEaEU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"jDfuKl19hdU7"},"outputs":[],"source":["\n","# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n","# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n","# THEN FEEL FREE TO DELETE THIS CELL.\n","# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n","# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n","# NOTEBOOK.\n","\n","import os\n","import sys\n","from tempfile import NamedTemporaryFile\n","from urllib.request import urlopen\n","from urllib.parse import unquote, urlparse\n","from urllib.error import HTTPError\n","from zipfile import ZipFile\n","import tarfile\n","import shutil\n","\n","CHUNK_SIZE = 40960\n","DATA_SOURCE_MAPPING = 'home-credit-credit-risk-model-stability:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F50160%2F7921029%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240722%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240722T081919Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D33958751a009fbaef5d65e13120efd1150f75e2aeaf80435db0e00272833932ba8279100f6571c2410a796194139c41516a535b7ee77bc5a4fb2d99e41396e524e6dcd57f2f94dece0b088e4dbfa677b1cb62b488265a23b237ae2305e2f3d49e50018cbee190820c0956c6a5529307d460a8bc034fb0740e39b6143a05147f823f886bc49179fe366c4c8ca3aa191b04687ac23f344ba3a6278fe9271dbaca3a2c6872d1a09d060fdd05ecbf1934826bc0bebf68500c9b9d97d53eac109292f47005ee957e07e6d436d2e7dd44d7c029859c8db0c3a88afc4fcc151b9d734efceaf0ac1a38e333123508da0ef601e9f79a1e8b8d8169c66817d2e0805d1bdd8'\n","\n","KAGGLE_INPUT_PATH='/kaggle/input'\n","KAGGLE_WORKING_PATH='/kaggle/working'\n","KAGGLE_SYMLINK='kaggle'\n","\n","!umount /kaggle/input/ 2> /dev/null\n","shutil.rmtree('/kaggle/input', ignore_errors=True)\n","os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n","os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n","\n","try:\n","  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n","except FileExistsError:\n","  pass\n","try:\n","  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n","except FileExistsError:\n","  pass\n","\n","for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n","    directory, download_url_encoded = data_source_mapping.split(':')\n","    download_url = unquote(download_url_encoded)\n","    filename = urlparse(download_url).path\n","    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n","    try:\n","        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n","            total_length = fileres.headers['content-length']\n","            print(f'Downloading {directory}, {total_length} bytes compressed')\n","            dl = 0\n","            data = fileres.read(CHUNK_SIZE)\n","            while len(data) > 0:\n","                dl += len(data)\n","                tfile.write(data)\n","                done = int(50 * dl / int(total_length))\n","                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n","                sys.stdout.flush()\n","                data = fileres.read(CHUNK_SIZE)\n","            if filename.endswith('.zip'):\n","              with ZipFile(tfile) as zfile:\n","                zfile.extractall(destination_path)\n","            else:\n","              with tarfile.open(tfile.name) as tarfile:\n","                tarfile.extractall(destination_path)\n","            print(f'\\nDownloaded and uncompressed: {directory}')\n","    except HTTPError as e:\n","        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n","        continue\n","    except OSError as e:\n","        print(f'Failed to load {download_url} to path {destination_path}')\n","        continue\n","\n","print('Data source import complete.')\n"]},{"cell_type":"code","source":["# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-02T02:35:08.028325Z\",\"iopub.execute_input\":\"2024-05-02T02:35:08.029189Z\",\"iopub.status.idle\":\"2024-05-02T02:35:12.426235Z\",\"shell.execute_reply.started\":\"2024-05-02T02:35:08.029130Z\",\"shell.execute_reply\":\"2024-05-02T02:35:12.424962Z\"}}\n","import sys\n","from pathlib import Path\n","import subprocess\n","import os\n","import gc\n","from glob import glob\n","\n","import joblib\n","\n","import numpy as np\n","import pandas as pd\n","import polars as pl\n","from datetime import datetime\n","# import seaborn as sns\n","# import matplotlib.pyplot as plt\n","\n","# from sklearn.model_selection import TimeSeriesSplit, GroupKFold, StratifiedGroupKFold\n","# from sklearn.base import BaseEstimator, RegressorMixin\n","from sklearn.metrics import roc_auc_score\n","import lightgbm as lgb\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","ROOT = '/kaggle/input/home-credit-credit-risk-model-stability'\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-02T02:35:12.428946Z\",\"iopub.execute_input\":\"2024-05-02T02:35:12.429574Z\",\"iopub.status.idle\":\"2024-05-02T02:35:12.447807Z\",\"shell.execute_reply.started\":\"2024-05-02T02:35:12.429528Z\",\"shell.execute_reply\":\"2024-05-02T02:35:12.446446Z\"}}\n","def reduce_mem_usage(df):\n","    \"\"\" iterate through all the columns of a dataframe and modify the data type\n","        to reduce memory usage.\n","    \"\"\"\n","    start_mem = df.memory_usage().sum() / 1024**2\n","    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n","\n","    for col in df.columns:\n","        col_type = df[col].dtype\n","        if str(col_type)==\"category\":\n","            continue\n","\n","        if col_type != object:\n","            c_min = df[col].min()\n","            c_max = df[col].max()\n","            if str(col_type)[:3] == 'int':\n","                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n","                    df[col] = df[col].astype(np.int8)\n","                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n","                    df[col] = df[col].astype(np.int16)\n","                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n","                    df[col] = df[col].astype(np.int32)\n","                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n","                    df[col] = df[col].astype(np.int64)\n","            else:\n","                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n","                    df[col] = df[col].astype(np.float16)\n","                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n","                    df[col] = df[col].astype(np.float32)\n","                else:\n","                    df[col] = df[col].astype(np.float64)\n","        else:\n","            df[col] = df[col].astype('category')\n","    end_mem = df.memory_usage().sum() / 1024**2\n","    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n","    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n","\n","    return df\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-02T02:35:12.449568Z\",\"iopub.execute_input\":\"2024-05-02T02:35:12.450235Z\",\"iopub.status.idle\":\"2024-05-02T02:35:12.475478Z\",\"shell.execute_reply.started\":\"2024-05-02T02:35:12.450195Z\",\"shell.execute_reply\":\"2024-05-02T02:35:12.474396Z\"}}\n","class Pipeline:\n","    @staticmethod\n","    def set_table_dtypes(df): #Standardize the dtype.\n","        for col in df.columns:\n","            if col in [\"case_id\", \"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n","                df = df.with_columns(pl.col(col).cast(pl.Int64))\n","            elif col in [\"date_decision\"]:\n","                df = df.with_columns(pl.col(col).cast(pl.Date))\n","            elif col[-1] in (\"P\", \"A\"):\n","                df = df.with_columns(pl.col(col).cast(pl.Float64))\n","            elif col[-1] in (\"M\",):\n","                df = df.with_columns(pl.col(col).cast(pl.String))\n","            elif col[-1] in (\"D\",):\n","                df = df.with_columns(pl.col(col).cast(pl.Date))\n","\n","        return df\n","\n","    @staticmethod\n","    def handle_dates(df): #Change the feature for D to the difference in days from date_decision.\n","        for col in df.columns:\n","            if (col[-1] in (\"D\",)) and ('count' not in col):\n","                df = df.with_columns(pl.col(col) - pl.col(\"date_decision\"))\n","                df = df.with_columns(pl.col(col).dt.total_days())\n","\n","        df = df.drop(\"date_decision\", \"MONTH\")\n","\n","        return df\n","\n","    @staticmethod\n","    def filter_cols(df): #Remove those with an average is_null exceeding 0.95 and those that do not fall within the range 1 < nunique < 200.\n","        for col in df.columns:\n","            # if col in [\"decision_month\", \"decision_weekday\"]:\n","            #     df = df.drop(col)\n","            #     continue\n","            # if ('amtde' in col) or ('bureau_b2' in col): # for ohter option\n","            #     continue\n","\n","            if col not in [\"target\", \"case_id\", \"WEEK_NUM\"]:\n","                isnull = df[col].is_null().mean()\n","                if isnull > 0.95:\n","                    df = df.drop(col)\n","\n","        for col in df.columns:\n","            # if '_depth2_' in col:\n","            #     continue\n","            if (col not in [\"target\", \"case_id\", \"WEEK_NUM\", ]) & (df[col].dtype == pl.String):\n","                freq = df[col].n_unique()\n","\n","                if (freq == 1) | (freq > 50):#50 #len(df) * 0.20): # 95 # fe4 down at fq20\n","                    df = df.drop(col)\n","\n","            # eliminate yaer, month feature\n","            # 644\n","            if (col[-1] not in [\"P\", \"A\", \"L\", \"M\"]) and (('month_' in col) or ('year_' in col)):# or ('num_group' in col):\n","            # if (('month_' in col) or ('year_' in col)):# or ('num_group' in col):\n","                df = df.drop(col)\n","\n","        return df\n","\n","\n","# 644 lb best\n","class Aggregator:\n","    @staticmethod\n","    def num_expr(df):\n","        cols = [col for col in df.columns if (col[-1] in (\"T\",\"L\",\"M\",\"D\",\"P\",\"A\")) or (\"num_group\" in col)]\n","\n","        expr_1 = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n","        expr_2 = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n","        # expr_3 = [pl.median(col).alias(f\"median_{col}\") for col in cols]\n","        # expr_3 = [pl.var(col).alias(f\"var_{col}\") for col in cols]+ [pl.sum(col).alias(f\"sum_{col}\") for col in cols]\n","        # expr_3 = [pl.last(col).alias(f\"last_{col}\") for col in cols] #+ \\\n","        #     [pl.first(col).alias(f\"first_{col}\") for col in cols] + \\\n","        #     [pl.mean(col).alias(f\"mean_{col}\") for col in cols] + \\\n","        #     [pl.std(col).alias(f\"std_{col}\") for col in cols]\n","        # expr_3 = [pl.count(col).alias(f\"count_{col}\") for col in cols]\n","\n","        cols2 = [col for col in df.columns if col[-1] in (\"L\", \"A\")]\n","        expr_3 = [pl.mean(col).alias(f\"mean_{col}\") for col in cols2] + [pl.std(col).alias(f\"std_{col}\") for col in cols2] + \\\n","            [pl.sum(col).alias(f\"sum_{col}\") for col in cols2] + [pl.median(col).alias(f\"median_{col}\") for col in cols2] # + \\\n","            # [pl.first(col).alias(f\"first_{col}\") for col in cols2] + [pl.last(col).alias(f\"last_{col}\") for col in cols2]\n","\n","        # BAD\n","        # cols3 = [col for col in df.columns if col[-1] in (\"A\")]\n","        # expr_4 = [pl.col(col).fill_null(strategy=\"zero\").apply(lambda x: x.max() - x.min()).alias(f\"max-min_gap_{col}\")\n","        #           for col in cols3]\n","        return expr_1 + expr_2 + expr_3 # + [pl.col(col).diff().last().alias(f\"diff-last_{col}\") for col in cols3] # + expr_4\n","\n","    @staticmethod\n","    def applprev2_exprs(df):\n","        cols = [col for col in df.columns if \"num_group\" not in col]\n","        # expr_1 = [pl.max(col).alias(f\"max_{col}\") for col in cols] + [pl.min(col).alias(f\"min_{col}\") for col in cols]\n","        expr_2 = [pl.first(col).alias(f\"first_{col}\") for col in cols]#  + [pl.last(col).alias(f\"last_{col}\") for col in cols]\n","        return []#expr_2\n","\n","    @staticmethod\n","    def bureau_a1(df):\n","        cols = [col for col in df.columns if (col[-1] in (\"T\",\"L\",\"M\",\"D\",\"P\",\"A\")) or (\"num_group\" in col)]\n","        expr_1 = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n","        expr_2 = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n","\n","        cols2 = [\n","            # bad\n","        'annualeffectiverate_199L', 'annualeffectiverate_63L',\n","        'contractsum_5085717L',\n","        'credlmt_230A', 'credlmt_935A',\n","        # 'debtoutstand_525A', 'debtoverdue_47A', 'dpdmax_139P', 'dpdmax_757P',\n","    #    'instlamount_768A', 'instlamount_852A',\n","    #    'interestrate_508L', 'monthlyinstlamount_332A',\n","    #    'monthlyinstlamount_674A',\n","            # good?\n","       'nominalrate_281L', 'nominalrate_498L',\n","       'numberofcontrsvalue_258L', 'numberofcontrsvalue_358L',\n","       'numberofinstls_229L', 'numberofinstls_320L',\n","       'numberofoutstandinstls_520L', 'numberofoutstandinstls_59L',\n","       'numberofoverdueinstlmax_1039L', 'numberofoverdueinstlmax_1151L',\n","       'numberofoverdueinstls_725L', 'numberofoverdueinstls_834L',\n","            # bad?\n","    #    'outstandingamount_354A', 'outstandingamount_362A', 'overdueamount_31A',\n","    #    'overdueamount_659A', 'overdueamountmax2_14A', 'overdueamountmax2_398A',\n","    #    'overdueamountmax_155A', 'overdueamountmax_35A',\n","        # bad ?\n","    #    'periodicityofpmts_1102L', 'periodicityofpmts_837L',\n","    #    'prolongationcount_1120L', 'prolongationcount_599L',\n","        # 520?\n","    #    'residualamount_488A', 'residualamount_856A', 'totalamount_6A',\n","    #    'totalamount_996A', 'totaldebtoverduevalue_178A',\n","    #    'totaldebtoverduevalue_718A', 'totaloutstanddebtvalue_39A',\n","    #    'totaloutstanddebtvalue_668A',\n","       ]\n","\n","        # .697\n","        # expr_3 = [pl.mean(col).alias(f\"mean_{col}\") for col in cols2] + [pl.std(col).alias(f\"std_{col}\") for col in cols2]\n","\n","        # .696\n","        # expr_3 = [pl.mean(col).alias(f\"mean_{col}\") for col in cols2]\n","\n","        # .697\n","        # expr_3 = [pl.std(col).alias(f\"std_{col}\") for col in cols2]\n","\n","        # .6985\n","        # expr_3 = [pl.sum(col).alias(f\"sum_{col}\") for col in cols2] + [pl.median(col).alias(f\"median_{col}\") for col in cols2]\n","\n","        # .696\n","        # expr_3 = [pl.sum(col).alias(f\"sum_{col}\") for col in cols2]\n","\n","        # .6981\n","        # expr_3 = [pl.median(col).alias(f\"median_{col}\") for col in cols2]\n","\n","        # .696\n","        # expr_3 = [pl.first(col).alias(f\"first_{col}\") for col in cols2] + [pl.last(col).alias(f\"last_{col}\") for col in cols2] # + \\\n","\n","        # .696\n","        # expr_3 = [pl.std(col).alias(f\"std_{col}\") for col in cols2] + [pl.median(col).alias(f\"median_{col}\") for col in cols2]\n","\n","        # .699\n","        # expr_3 = [pl.mean(col).alias(f\"mean_{col}\") for col in cols2] + [pl.std(col).alias(f\"std_{col}\") for col in cols2] + \\\n","        #     [pl.sum(col).alias(f\"sum_{col}\") for col in cols2] + [pl.median(col).alias(f\"median_{col}\") for col in cols2]\n","\n","        expr_3 = [pl.mean(col).alias(f\"mean_{col}\") for col in cols2] + [pl.std(col).alias(f\"std_{col}\") for col in cols2] + \\\n","            [pl.sum(col).alias(f\"sum_{col}\") for col in cols2] + [pl.median(col).alias(f\"median_{col}\") for col in cols2] + \\\n","            [pl.first(col).alias(f\"first_{col}\") for col in cols2] # + [pl.last(col).alias(f\"last_{col}\") for col in cols2] # not applied\n","\n","\n","\n","        # expr_3 = [pl.col(col).fill_null(strategy=\"zero\").apply(lambda x: x.max() - x.min()).alias(f\"max-min_gap_depth2_{col}\") for col in cols2]\n","        return expr_1 + expr_2 + expr_3\n","\n","\n","    @staticmethod\n","    def bureau_b1(df):  # 0.95에서 미적용 중 # 36500\n","        # cols = [col for col in df.columns if (col[-1] in (\"T\",\"L\",\"M\",\"D\",\"P\",\"A\")) or (\"num_group\" in col)]\n","\n","        # expr_1 = [pl.max(col).alias(f\"bureau_b1_max_{col}\") for col in cols]\n","        # expr_2 = [pl.min(col).alias(f\"bureau_b1_min_{col}\") for col in cols]\n","\n","        # return expr_1 + expr_2 #  + expr_3\n","        return []\n","\n","\n","    @staticmethod\n","    def bureau_b2(df):  # 0.95에서 미적용 중 # 36500\n","        # cols = [col for col in df.columns if (col[-1] in (\"T\",\"L\",\"M\",\"D\",\"P\",\"A\")) or (\"num_group\" in col)]\n","\n","        # expr_1 = [pl.max(col).alias(f\"bureau_b2_max_{col}\") for col in cols]\n","        # expr_2 = [pl.min(col).alias(f\"bureau_b2_min_{col}\") for col in cols]\n","\n","        # return expr_1 + expr_2 #  + expr_3\n","        return []\n","\n","\n","    @staticmethod\n","    def deposit_exprs(df):\n","        cols = [col for col in df.columns if (col[-1] in (\"T\",\"L\",\"M\",\"D\",\"P\",\"A\")) or (\"num_group\" in col)]\n","        expr_1 = [pl.max(col).alias(f\"max_{col}\") for col in cols] + [pl.min(col).alias(f\"min_{col}\") for col in cols] # + \\\n","            # [pl.last(col).alias(f\"last_{col}\") for col in cols]\n","            # [pl.mean(col).alias(f\"mean_{col}\") for col in cols] # + \\\n","            # [pl.std(col).alias(f\"std_{col}\") for col in cols]  + \\\n","\n","            # [pl.last(col).alias(f\"last_{col}\") for col in cols]\n","        # expr_2 = [pl.first('openingdate_857D').alias(f'first_openingdate_857D')] + [pl.last('openingdate_857D').alias(f'last_openingdate_857D')]\n","\n","        return expr_1 # + expr_2 #+ expr_ngmax\n","\n","    @staticmethod\n","    def debitcard_exprs(df):\n","        # cols = [col for col in df.columns if (col[-1] in [\"A\"])]\n","        cols = [col for col in df.columns if (col[-1] in (\"T\",\"L\",\"M\",\"D\",\"P\",\"A\")) or (\"num_group\" in col)]\n","        expr_1 = [pl.max(col).alias(f\"max_{col}\") for col in cols] + [pl.min(col).alias(f\"min_{col}\") for col in cols]\n","            # [pl.mean(col).alias(f\"mean_{col}\") for col in cols] + \\\n","            # [pl.std(col).alias(f\"std_{col}\") for col in cols]\n","        # expr_2 = [pl.first('openingdate_857D').alias(f'first_openingdate_857D')] + [pl.last('openingdate_857D').alias(f'last_openingdate_857D')]\n","\n","        return expr_1 # + expr_2 #+ expr_ngmax\n","        # return expr_1\n","\n","\n","    @staticmethod\n","    def person_expr(df):\n","        cols1 = ['empl_employedtotal_800L', 'empl_employedfrom_271D', 'empl_industry_691L',\n","                 'familystate_447L', 'incometype_1044T', 'sex_738L', 'housetype_905L', 'housingtype_772L',\n","                 'isreference_387L', 'birth_259D', ]\n","        # cols1 = [col for col in df.columns]\n","        expr_1 = [pl.first(col).alias(f\"first_{col}\") for col in cols1]\n","\n","        expr_2 = [pl.col(\"mainoccupationinc_384A\").max().alias(\"mainoccupationinc_384A_max\"),\n","                  pl.col(\"mainoccupationinc_384A\").filter(pl.col(\"incometype_1044T\") == \"SELFEMPLOYED\").max().alias(\"mainoccupationinc_384A_any_selfemployed\")]\n","\n","        # No Effect ...\n","        # cols = ['personindex_1023L', 'persontype_1072L', 'persontype_792L']\n","        # expr_3 = [pl.col(col).last().alias(f\"last_{col}\") for col in cols] + [pl.col(col).drop_nulls().mean().alias(f\"mean_{col}\") for col in cols]\n","\n","        # cols2 = [col for col in df.columns if col not in cols1]\n","        # expr_4 = [pl.max(col).alias(f\"max_{col}\") for col in cols2] + [pl.min(col).alias(f\"min_{col}\") for col in cols2] #  good at cv, bad at lb ?\n","            # [pl.col(col).drop_nulls().last().alias(f\"last_{col}\") for col in cols2] + [pl.col(col).drop_nulls().first().alias(f\"first_{col}\") for col in cols2] # no effect\n","\n","        return expr_1 + expr_2 # + expr_4 # + expr_3\n","\n","    @staticmethod\n","    def person_2_expr(df):\n","        # cols = [col for col in df.columns]\n","        cols = ['empls_economicalst_849M', 'empls_employedfrom_796D', 'empls_employer_name_740M'] # + \\\n","            # ['relatedpersons_role_762T', 'conts_role_79M']\n","            # ['addres_district_368M', 'addres_role_871L', 'addres_zip_823M']\n","\n","        expr_1 = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n","        expr_2 = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n","\n","        # BAD\n","        # expr_ngc = [pl.count(\"num_group2\").alias(f\"count_num_group2\")]\n","        # cols2 = [col for col in df.columns if (col in (\"num_group1\", \"num_group2\"))]\n","        # expr_ngmax = [pl.min(col).alias(f\"min_{col}\") for col in cols2] + [pl.max(col).alias(f\"max_{col}\") for col in cols2]\n","\n","        # cols2 = [col for col in df.columns if col not in cols]\n","        # # expr_3 = [pl.max(col).alias(f\"max_{col}\") for col in cols2] + [pl.min(col).alias(f\"min_{col}\") for col in cols2] # no effect\n","        # expr_3 = [pl.col(col).drop_nulls().last().alias(f\"last_{col}\") for col in cols2] # no effect\n","\n","        return expr_1 + expr_2 # + expr_3# + expr_ngc\n","\n","    @staticmethod\n","    def other_expr(df):\n","        expr_1 = [pl.first(col).alias(f\"__other_{col}\") for col in df.columns if ('num_group' not in col) and (col != 'case_id')]\n","        # cols1 = ['amtdepositbalance_4809441A', 'amtdepositincoming_4809444A', 'amtdepositoutgoing_4809442A']\n","        # expr_1 = [pl.last(col).alias(f\"last_{col}\") for col in cols1]\n","        # cols2 = ['amtdebitincoming_4809443A', 'amtdebitoutgoing_4809440A']\n","        # expr_3 = [(pl.col('amtdebitincoming_4809443A') - pl.col('amtdebitoutgoing_4809440A')).alias('amtdebit_incoming-outgoing')]\n","        return expr_1 # + expr_2 + expr_3\n","\n","\n","    @staticmethod\n","    def tax_a_exprs(df):\n","        cols = [col for col in df.columns if (col[-1] in (\"T\",\"L\",\"M\",\"D\",\"P\",\"A\")) or (\"num_group\" in col)]\n","        expr_1 = [pl.max(col).alias(f\"max_{col}\") for col in cols] + [pl.min(col).alias(f\"min_{col}\") for col in cols] + \\\n","            [pl.last(col).alias(f\"last_{col}\") for col in cols] + \\\n","            [pl.first(col).alias(f\"first_{col}\") for col in cols] + \\\n","            [pl.mean(col).alias(f\"mean_{col}\") for col in cols] + \\\n","            [pl.std(col).alias(f\"std_{col}\") for col in cols]\n","        # expr_1 = [pl.max(col).alias(f\"max_{col}\") for col in ['amount_4527230A', 'recorddate_4527225D', 'num_group1']] + \\\n","        #     [pl.min(col).alias(f\"min_{col}\") for col in ['amount_4527230A', 'recorddate_4527225D', ]] + \\\n","        #     [pl.mean(col).alias(f\"mean_{col}\") for col in ['amount_4527230A']] + \\\n","        #     [pl.std(col).alias(f\"std_{col}\") for col in ['amount_4527230A']] + \\\n","        #     [pl.last(col).alias(f\"last_{col}\") for col in ['amount_4527230A', 'recorddate_4527225D', 'name_4527232M']] + \\\n","        #     [pl.first(col).alias(f\"first_{col}\") for col in ['amount_4527230A', 'recorddate_4527225D', 'name_4527232M']] # BAD?\n","\n","        expr_4 = [pl.col(col).fill_null(strategy=\"zero\").apply(lambda x: x.max() - x.min()).alias(f\"max-min_gap_depth2_{col}\") for col in ['amount_4527230A']]\n","\n","        return expr_1 + expr_4\n","\n","\n","    @staticmethod\n","    def bureau_a2(df): # 122만\n","        # cols = ['collater_valueofguarantee_1124L', 'pmts_dpd_1073P', 'pmts_overdue_1140A',]\n","        cols = [col for col in df.columns if (col[-1] in (\"T\",\"L\",\"M\",\"D\",\"P\",\"A\")) or (\"num_group\" in col)]\n","\n","        expr_1 = [pl.max(col).alias(f\"max_depth2_{col}\") for col in cols]\n","        expr_2 = [pl.min(col).alias(f\"min_depth2_{col}\") for col in cols]\n","        expr_3 = [pl.mean(col).alias(f\"mean_depth2_{col}\") for col in cols] + \\\n","            [pl.std(col).alias(f\"std_{col}\") for col in cols]\n","        # expr_ngs = [pl.max(col).alias(f\"max_{col}\") for col in ['num_group1', 'num_group2', ]]\n","\n","        expr_4 = [pl.col(col).fill_null(strategy=\"zero\").apply(lambda x: x.max() - x.min()).alias(f\"max-min_gap_depth2_{col}\") for col in ['collater_valueofguarantee_1124L', 'pmts_dpd_1073P', 'pmts_overdue_1140A',]]\n","\n","        expr_ngc = [pl.count(\"num_group2\").alias(f\"count_depth2_a2_num_group2\")]\n","\n","        # expr_5 = [pl.last(col).alias(f\"last_{col}\") for col in cols] + \\\n","        #     [pl.first(col).alias(f\"first_{col}\") for col in cols] + \\\n","        #     [pl.std(col).alias(f\"std_{col}\") for col in cols]\n","\n","        return expr_1 + expr_2 + expr_3 + expr_4 + expr_ngc # + expr_5\n","\n","    @staticmethod\n","    def get_exprs(df):\n","        exprs = Aggregator.num_expr(df)\n","\n","        return exprs\n","\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-02T02:35:12.546131Z\",\"iopub.execute_input\":\"2024-05-02T02:35:12.547239Z\",\"iopub.status.idle\":\"2024-05-02T02:35:12.573617Z\",\"shell.execute_reply.started\":\"2024-05-02T02:35:12.547191Z\",\"shell.execute_reply\":\"2024-05-02T02:35:12.572323Z\"}}\n","def agg_by_case(path, df):\n","    path = str(path)\n","    if '_applprev_1' in path:\n","        df = df.sort(\"num_group1\").group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n","\n","#     elif '_applprev_2' in path:\n","#         df = df.group_by(\"case_id\").agg(Aggregator.applprev2_exprs(df))\n","\n","    elif '_credit_bureau_a_1' in path:\n","        df = df.sort(\"num_group1\").group_by(\"case_id\").agg(Aggregator.bureau_a1(df))\n","\n","    elif '_credit_bureau_b_1' in path:\n","        df = df.sort(\"num_group1\").group_by(\"case_id\").agg(Aggregator.bureau_b1(df))\n","\n","    elif '_deposit_1' in path:\n","        df = df.sort(\"num_group1\").group_by(\"case_id\").agg(Aggregator.deposit_exprs(df))\n","    elif '_debitcard_1' in path:\n","        df = df.sort(\"num_group1\").group_by(\"case_id\").agg(Aggregator.debitcard_exprs(df))\n","\n","    elif '_tax_registry_a' in path:\n","        df = df.sort(\"num_group1\").group_by(\"case_id\").agg(Aggregator.tax_a_exprs(df))\n","    elif '_tax_registry_b' in path:\n","        df = df.sort(\"num_group1\").group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n","    elif '_tax_registry_c' in path:\n","        df = df.sort(\"num_group1\").group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n","\n","    elif '_other_1' in path:\n","        df = df.sort(\"num_group1\").group_by(\"case_id\").agg(Aggregator.other_expr(df))\n","    elif '_person_1' in path:\n","        df = df.sort(\"num_group1\").group_by(\"case_id\").agg(Aggregator.person_expr(df))\n","    elif '_person_2' in path:\n","        df = df.group_by(\"case_id\").agg(Aggregator.person_2_expr(df))\n","\n","    elif '_credit_bureau_a_2' in path:\n","        df = df.group_by(\"case_id\").agg(Aggregator.bureau_a2(df))\n","    elif '_credit_bureau_b_2' in path:\n","        df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n","\n","    return df\n","\n","def read_file(path, depth=None):\n","    df = pl.read_parquet(path)\n","    df = df.pipe(Pipeline.set_table_dtypes)\n","\n","    if depth in [1, 2]:\n","        df = agg_by_case(path, df)\n","\n","    return df\n","\n","def read_files(regex_path, depth=None):\n","    print(regex_path)\n","    chunks = []\n","    for path in glob(str(regex_path)):\n","        df = pl.read_parquet(path)\n","        df = df.pipe(Pipeline.set_table_dtypes)\n","        if depth in [1, 2]:\n","            df = agg_by_case(path, df)\n","        chunks.append(df)\n","        #     del df\n","        #     gc.collect()\n","        #     print('delete chunk')\n","\n","    df = pl.concat(chunks, how=\"vertical_relaxed\")\n","    df = df.unique(subset=[\"case_id\"])\n","\n","    return df\n","\n","def feature_eng(df_base, depth_0, depth_1, depth_2):\n","    df_base = (\n","        df_base.with_columns(\n","            decision_month = pl.col(\"date_decision\").dt.month(),\n","            decision_weekday = pl.col(\"date_decision\").dt.weekday(),\n","        )\n","    )\n","\n","    for i, df in enumerate(depth_0 + depth_1 + depth_2):\n","        df_base = df_base.join(df, how=\"left\", on=\"case_id\", suffix=f\"_{i}\")\n","\n","    df_base = df_base.pipe(Pipeline.handle_dates)\n","    return df_base\n","\n","def to_pandas(df_data, cat_cols=None):\n","    df_data = df_data.to_pandas()\n","    print(df_data.info())\n","    if cat_cols is None:\n","        cat_cols = list(df_data.select_dtypes(\"object\").columns)\n","        # cat_cols = [c for c in cat_cols if 'diff_' not in c]\n","\n","    df_data[cat_cols] = df_data[cat_cols].astype(\"category\")\n","\n","    return df_data, cat_cols\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-02T02:35:12.575798Z\",\"iopub.execute_input\":\"2024-05-02T02:35:12.576686Z\",\"iopub.status.idle\":\"2024-05-02T02:35:12.593361Z\",\"shell.execute_reply.started\":\"2024-05-02T02:35:12.576632Z\",\"shell.execute_reply\":\"2024-05-02T02:35:12.591807Z\"}}\n","ROOT            = Path(\"/kaggle/input/home-credit-credit-risk-model-stability\")\n","\n","TRAIN_DIR       = ROOT / \"parquet_files\" / \"train\"\n","TEST_DIR        = ROOT / \"parquet_files\" / \"test\"\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-02T02:35:12.595304Z\",\"iopub.execute_input\":\"2024-05-02T02:35:12.596095Z\",\"iopub.status.idle\":\"2024-05-02T02:35:12.606239Z\",\"shell.execute_reply.started\":\"2024-05-02T02:35:12.596031Z\",\"shell.execute_reply\":\"2024-05-02T02:35:12.604446Z\"}}\n","# data_store = {\n","#     \"df_base\": read_file(TRAIN_DIR / \"train_base.parquet\"),\n","#     \"depth_0\": [\n","#         read_file(TRAIN_DIR / \"train_static_cb_0.parquet\"),\n","#         read_files(TRAIN_DIR / \"train_static_0_*.parquet\"),\n","\n","#     ],\n","#     \"depth_1\": [\n","#         read_files(TRAIN_DIR / \"train_applprev_1_*.parquet\", 1),\n","#         read_files(TRAIN_DIR / \"train_credit_bureau_a_1_*.parquet\", 1),\n","#         read_file(TRAIN_DIR / \"train_credit_bureau_b_1.parquet\", 1),\n","#         read_file(TRAIN_DIR / \"train_deposit_1.parquet\", 1),\n","#         read_file(TRAIN_DIR / \"train_debitcard_1.parquet\", 1),\n","#         read_file(TRAIN_DIR / \"train_tax_registry_a_1.parquet\", 1),\n","#         # read_file(TRAIN_DIR / \"train_tax_registry_b_1.parquet\", 1),\n","#         # read_file(TRAIN_DIR / \"train_tax_registry_c_1.parquet\", 1),\n","#         read_file(TRAIN_DIR / \"train_person_1.parquet\", 1),\n","#         read_file(TRAIN_DIR / \"train_other_1.parquet\", 1),\n","#     ],\n","#     \"depth_2\": [\n","#         read_files(TRAIN_DIR / \"train_credit_bureau_a_2_*.parquet\", 2),\n","#         read_file(TRAIN_DIR / \"train_credit_bureau_b_2.parquet\", 2),\n","#     ]\n","# }\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-02T02:35:12.608596Z\",\"iopub.execute_input\":\"2024-05-02T02:35:12.609262Z\",\"iopub.status.idle\":\"2024-05-02T02:35:12.622765Z\",\"shell.execute_reply.started\":\"2024-05-02T02:35:12.609219Z\",\"shell.execute_reply\":\"2024-05-02T02:35:12.621598Z\"}}\n","# df_train = feature_eng(**data_store)\n","# print(\"train data shape:\\t\", df_train.shape)\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-02T02:35:12.624675Z\",\"iopub.execute_input\":\"2024-05-02T02:35:12.625494Z\",\"iopub.status.idle\":\"2024-05-02T02:35:13.332636Z\",\"shell.execute_reply.started\":\"2024-05-02T02:35:12.625453Z\",\"shell.execute_reply\":\"2024-05-02T02:35:13.330617Z\"}}\n","data_store = {\n","    \"df_base\": read_file(TEST_DIR / \"test_base.parquet\"),\n","    \"depth_0\": [\n","        read_file(TEST_DIR / \"test_static_cb_0.parquet\"),\n","        read_files(TEST_DIR / \"test_static_0_*.parquet\"),\n","    ],\n","    \"depth_1\": [\n","        read_files(TEST_DIR / \"test_applprev_1_*.parquet\", 1),\n","        read_files(TEST_DIR / \"test_credit_bureau_a_1_*.parquet\", 1),\n","        read_file(TEST_DIR / \"test_credit_bureau_b_1.parquet\", 1),\n","        read_file(TEST_DIR / \"test_deposit_1.parquet\", 1),\n","        read_file(TEST_DIR / \"test_debitcard_1.parquet\", 1),\n","        read_file(TEST_DIR / \"test_tax_registry_a_1.parquet\", 1),\n","        read_file(TEST_DIR / \"test_tax_registry_b_1.parquet\", 1),\n","        read_file(TEST_DIR / \"test_tax_registry_c_1.parquet\", 1),\n","        read_file(TEST_DIR / \"test_person_1.parquet\", 1),\n","        read_file(TEST_DIR / \"test_other_1.parquet\", 1),\n","    ],\n","    \"depth_2\": [\n","        read_files(TEST_DIR / \"test_credit_bureau_a_2_*.parquet\", 2),\n","        read_file(TEST_DIR / \"test_credit_bureau_b_2.parquet\", 2),\n","        read_file(TEST_DIR / \"test_person_2.parquet\", 2),\n","    ]\n","}\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-02T02:35:13.337192Z\",\"iopub.execute_input\":\"2024-05-02T02:35:13.337534Z\",\"iopub.status.idle\":\"2024-05-02T02:35:13.454908Z\",\"shell.execute_reply.started\":\"2024-05-02T02:35:13.337506Z\",\"shell.execute_reply\":\"2024-05-02T02:35:13.452272Z\"}}\n","df_test = feature_eng(**data_store)\n","print(\"test data shape:\\t\", df_test.shape)\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-02T02:35:13.456179Z\",\"iopub.execute_input\":\"2024-05-02T02:35:13.457134Z\",\"iopub.status.idle\":\"2024-05-02T02:35:16.140282Z\",\"shell.execute_reply.started\":\"2024-05-02T02:35:13.457098Z\",\"shell.execute_reply\":\"2024-05-02T02:35:16.139023Z\"}}\n","# load models\n","cat_cols = joblib.load('/kaggle/input/hclgb-models/cat_cols.pickle')\n","ls_models = glob(os.path.join('/kaggle/input/hclgb-models', \"*.pkl\"))\n","models = [joblib.load(fn) for fn in ls_models]\n","\n","lgb_features = models[0].feature_name_\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-02T02:35:16.141849Z\",\"iopub.execute_input\":\"2024-05-02T02:35:16.142311Z\",\"iopub.status.idle\":\"2024-05-02T02:35:16.154451Z\",\"shell.execute_reply.started\":\"2024-05-02T02:35:16.142271Z\",\"shell.execute_reply\":\"2024-05-02T02:35:16.152901Z\"}}\n","# Drop the insignificant features\n","# df_train = df_train.pipe(Pipeline.filter_cols)\n","# df_test = df_test.select([col for col in df_train.columns if col != \"target\"])\n","\n","df_test = df_test.select(['case_id'] + lgb_features)\n","\n","# print(\"train data shape:\\t\", df_train.shape)\n","print(\"test data shape:\\t\", df_test.shape)\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-02T02:35:16.156187Z\",\"iopub.execute_input\":\"2024-05-02T02:35:16.156653Z\",\"iopub.status.idle\":\"2024-05-02T02:35:16.268030Z\",\"shell.execute_reply.started\":\"2024-05-02T02:35:16.156613Z\",\"shell.execute_reply\":\"2024-05-02T02:35:16.266683Z\"}}\n","del data_store\n","gc.collect()\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-02T02:35:16.269551Z\",\"iopub.execute_input\":\"2024-05-02T02:35:16.270017Z\",\"iopub.status.idle\":\"2024-05-02T02:35:16.713460Z\",\"shell.execute_reply.started\":\"2024-05-02T02:35:16.269984Z\",\"shell.execute_reply\":\"2024-05-02T02:35:16.712171Z\"}}\n","df_test, _ = to_pandas(df_test, cat_cols)\n","df_test = reduce_mem_usage(df_test)\n","# display(df_test.head())\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-02T02:35:16.715531Z\",\"iopub.execute_input\":\"2024-05-02T02:35:16.716484Z\",\"iopub.status.idle\":\"2024-05-02T02:35:16.873638Z\",\"shell.execute_reply.started\":\"2024-05-02T02:35:16.716445Z\",\"shell.execute_reply\":\"2024-05-02T02:35:16.872297Z\"}}\n","df_test.drop(columns=[\"case_id\"]).to_csv('test_data.csv', index=False)\n","del df_test\n","gc.collect()\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-02T02:35:16.877402Z\",\"iopub.execute_input\":\"2024-05-02T02:35:16.877778Z\",\"iopub.status.idle\":\"2024-05-02T02:35:16.882970Z\",\"shell.execute_reply.started\":\"2024-05-02T02:35:16.877749Z\",\"shell.execute_reply\":\"2024-05-02T02:35:16.881593Z\"}}\n","# %reset -f\n","# !mkdir -p submission_data\n","# !mv test_data.csv submission_data/test_data.csv  # move file to submission_data dir\n","# import glob\n","# for f in glob.glob('*'):\n","#     if not f.startswith('submission_data'):# delete all files if path not starts with submission_data\n","#         !rm -rf {f}\n","\n","# %% [markdown]\n","# ### Submission\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-02T02:35:16.884247Z\",\"iopub.execute_input\":\"2024-05-02T02:35:16.884557Z\",\"iopub.status.idle\":\"2024-05-02T02:35:17.128625Z\",\"shell.execute_reply.started\":\"2024-05-02T02:35:16.884532Z\",\"shell.execute_reply\":\"2024-05-02T02:35:17.127501Z\"}}\n","import sys\n","from pathlib import Path\n","import subprocess\n","import os\n","import gc\n","from glob import glob\n","\n","import joblib\n","\n","import numpy as np\n","import pandas as pd\n","import polars as pl\n","from datetime import datetime\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import TimeSeriesSplit, GroupKFold, StratifiedGroupKFold\n","from sklearn.base import BaseEstimator, RegressorMixin\n","from sklearn.metrics import roc_auc_score\n","import lightgbm as lgb\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","ROOT = '/kaggle/input/home-credit-credit-risk-model-stability'\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-02T02:35:17.130422Z\",\"iopub.execute_input\":\"2024-05-02T02:35:17.130832Z\",\"iopub.status.idle\":\"2024-05-02T02:35:18.386427Z\",\"shell.execute_reply.started\":\"2024-05-02T02:35:17.130724Z\",\"shell.execute_reply\":\"2024-05-02T02:35:18.385160Z\"}}\n","# load models\n","cat_cols = joblib.load('/kaggle/input/hclgb-models/cat_cols.pickle')\n","ls_models = glob(os.path.join('/kaggle/input/hclgb-models', \"*.pkl\"))\n","models = [joblib.load(fn) for fn in ls_models]\n","\n","print(len(models), models)\n","\n","lgb_features = models[0].feature_name_\n","len(lgb_features), lgb_features\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-02T02:35:18.387843Z\",\"iopub.execute_input\":\"2024-05-02T02:35:18.388266Z\",\"iopub.status.idle\":\"2024-05-02T02:35:18.393960Z\",\"shell.execute_reply.started\":\"2024-05-02T02:35:18.388233Z\",\"shell.execute_reply\":\"2024-05-02T02:35:18.392612Z\"}}\n","def set_categoricals(df_data, cat_cols):\n","    df_data[cat_cols] = df_data[cat_cols].astype(\"category\")\n","    return df_data\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-02T02:35:18.395446Z\",\"iopub.execute_input\":\"2024-05-02T02:35:18.395875Z\",\"iopub.status.idle\":\"2024-05-02T02:35:18.411450Z\",\"shell.execute_reply.started\":\"2024-05-02T02:35:18.395837Z\",\"shell.execute_reply\":\"2024-05-02T02:35:18.410136Z\"}}\n","def lgb_prediction(feats, models):\n","    predictions = np.zeros(len(feats))\n","    for model in models:\n","        p = model.predict_proba(feats)[:, 1]\n","        predictions += p/len(models)\n","    return predictions\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-02T02:35:18.414029Z\",\"iopub.execute_input\":\"2024-05-02T02:35:18.414366Z\",\"iopub.status.idle\":\"2024-05-02T02:35:18.988681Z\",\"shell.execute_reply.started\":\"2024-05-02T02:35:18.414341Z\",\"shell.execute_reply\":\"2024-05-02T02:35:18.987333Z\"}}\n","CHUNK_SIZE = 10 ** 6\n","reader = pd.read_csv('/kaggle/working/test_data.csv', chunksize=CHUNK_SIZE)\n","y_pred = []\n","for df_chunk in reader:\n","    # p = predictor.predict_proba(df_chunk).iloc[:, 1].values\n","    df_chunk = set_categoricals(df_chunk, cat_cols)\n","    p = lgb_prediction(df_chunk, models)\n","    y_pred.append(p)\n","\n","y_pred = np.concatenate(y_pred, axis=0)\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-02T02:35:18.989932Z\",\"iopub.execute_input\":\"2024-05-02T02:35:18.991126Z\",\"iopub.status.idle\":\"2024-05-02T02:35:19.103530Z\",\"shell.execute_reply.started\":\"2024-05-02T02:35:18.991087Z\",\"shell.execute_reply\":\"2024-05-02T02:35:19.102143Z\"}}\n","del reader\n","gc.collect()\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-02T02:35:19.104846Z\",\"iopub.execute_input\":\"2024-05-02T02:35:19.105233Z\",\"iopub.status.idle\":\"2024-05-02T02:35:19.122471Z\",\"shell.execute_reply.started\":\"2024-05-02T02:35:19.105195Z\",\"shell.execute_reply\":\"2024-05-02T02:35:19.121172Z\"}}\n","df_subm = pd.read_csv(f\"{ROOT}/sample_submission.csv\")\n","df_subm = df_subm.set_index(\"case_id\")\n","\n","df_subm[\"score\"] = y_pred#lgb_pred\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-02T02:35:19.123943Z\",\"iopub.execute_input\":\"2024-05-02T02:35:19.124599Z\",\"iopub.status.idle\":\"2024-05-02T02:35:19.139836Z\",\"shell.execute_reply.started\":\"2024-05-02T02:35:19.124567Z\",\"shell.execute_reply\":\"2024-05-02T02:35:19.138811Z\"}}\n","df_subm.to_csv(\"submission.csv\")\n","print(df_subm)"],"metadata":{"id":"cZKoueCkhyiD"},"execution_count":null,"outputs":[]}]}