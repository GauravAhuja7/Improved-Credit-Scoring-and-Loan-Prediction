{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPHPiVPzQwYXnN2/pkkHsT+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["\n","import os\n","import sys\n","from tempfile import NamedTemporaryFile\n","from urllib.request import urlopen\n","from urllib.parse import unquote, urlparse\n","from urllib.error import HTTPError\n","from zipfile import ZipFile\n","import tarfile\n","import shutil\n","\n","CHUNK_SIZE = 40960\n","DATA_SOURCE_MAPPING = 'home-credit-credit-risk-model-stability:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F50160%2F7921029%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240722%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240722T081527Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D00ed002ef02223f3123ba889ee9d93d70d132d190b575b91a3a6da4e4ec60b4bf5eb89250fe8d6d7f623000e772364d911c74b4cb6ea8c086e44586b49494792d218b02586174d8497cac771ddd3a224b54d74f4bcc109e24a7683d9cbb56b40ee61cd25b67d220093e3ecb759fc1730d4e829a78dbb8f2a1fdc82487be0b851597db803820fc4dc09a099a6181f346f97f89c7442adddd62254cd14b52277fb2c4be4e55912152193e74c92237c686a5f5edde9174dd9d9924a137502c892a17a055bd0244b1077e99619730fbc6d6208b2b8311bcc74ba2f6b1d1437bbf2ebd24c78fa32b77700db3d9f416420549ba000c0ea48644ecb4ef0d9912f22f7b0'\n","\n","KAGGLE_INPUT_PATH='/kaggle/input'\n","KAGGLE_WORKING_PATH='/kaggle/working'\n","KAGGLE_SYMLINK='kaggle'\n","\n","!umount /kaggle/input/ 2> /dev/null\n","shutil.rmtree('/kaggle/input', ignore_errors=True)\n","os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n","os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n","\n","try:\n","  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n","except FileExistsError:\n","  pass\n","try:\n","  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n","except FileExistsError:\n","  pass\n","\n","for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n","    directory, download_url_encoded = data_source_mapping.split(':')\n","    download_url = unquote(download_url_encoded)\n","    filename = urlparse(download_url).path\n","    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n","    try:\n","        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n","            total_length = fileres.headers['content-length']\n","            print(f'Downloading {directory}, {total_length} bytes compressed')\n","            dl = 0\n","            data = fileres.read(CHUNK_SIZE)\n","            while len(data) > 0:\n","                dl += len(data)\n","                tfile.write(data)\n","                done = int(50 * dl / int(total_length))\n","                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n","                sys.stdout.flush()\n","                data = fileres.read(CHUNK_SIZE)\n","            if filename.endswith('.zip'):\n","              with ZipFile(tfile) as zfile:\n","                zfile.extractall(destination_path)\n","            else:\n","              with tarfile.open(tfile.name) as tarfile:\n","                tarfile.extractall(destination_path)\n","            print(f'\\nDownloaded and uncompressed: {directory}')\n","    except HTTPError as e:\n","        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n","        continue\n","    except OSError as e:\n","        print(f'Failed to load {download_url} to path {destination_path}')\n","        continue\n","\n","print('Data source import complete.')\n"],"metadata":{"id":"Dr6l_X9MhG6f"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z5q4LOJhgXxt"},"outputs":[],"source":["# %% [code]\n","# %% [code]\n","# %% [code]\n","# %% [markdown] {\"papermill\":{\"duration\":0.006713,\"end_time\":\"2024-02-10T04:58:28.609783\",\"exception\":false,\"start_time\":\"2024-02-10T04:58:28.60307\",\"status\":\"completed\"},\"tags\":[]}\n","# # Dependencies\n","\n","# %% [code] {\"papermill\":{\"duration\":6.303403,\"end_time\":\"2024-02-10T04:58:34.920027\",\"exception\":false,\"start_time\":\"2024-02-10T04:58:28.616624\",\"status\":\"completed\"},\"tags\":[],\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-05T00:46:11.278321Z\",\"iopub.execute_input\":\"2024-05-05T00:46:11.279077Z\",\"iopub.status.idle\":\"2024-05-05T00:46:19.734115Z\",\"shell.execute_reply.started\":\"2024-05-05T00:46:11.279043Z\",\"shell.execute_reply\":\"2024-05-05T00:46:19.733127Z\"}}\n","import os\n","import gc\n","from glob import glob\n","from pathlib import Path\n","from datetime import datetime\n","import numpy as np\n","import pandas as pd\n","import polars as pl\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import joblib\n","import lightgbm as lgb\n","import torch\n","import torch.nn as nn\n","\n","from sklearn.model_selection import StratifiedGroupKFold\n","from sklearn.metrics import roc_auc_score\n","from sklearn.ensemble import VotingClassifier\n","from sklearn.preprocessing import LabelEncoder\n","\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","\n","# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-05-05T00:46:19.735663Z\",\"iopub.execute_input\":\"2024-05-05T00:46:19.736281Z\",\"iopub.status.idle\":\"2024-05-05T00:46:20.928926Z\",\"shell.execute_reply.started\":\"2024-05-05T00:46:19.736254Z\",\"shell.execute_reply\":\"2024-05-05T00:46:20.928019Z\"}}\n","from catboost import CatBoostClassifier, Pool\n","\n","save_full_path = '/kaggle/input/hc-catboost-models'\n","\n","# load models\n","cat_cols = joblib.load(f'{save_full_path}/cat_cols.pickle')\n","ls_models = glob(os.path.join(f'{save_full_path}/', \"catboost_model_fold_*\"))\n","models = [CatBoostClassifier().load_model(fn, format=\"cbm\") for fn in ls_models]\n","\n","cat_features = models[0].feature_names_\n","len(cat_features), len(models)\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-05T00:46:20.930161Z\",\"iopub.execute_input\":\"2024-05-05T00:46:20.930517Z\",\"iopub.status.idle\":\"2024-05-05T00:46:20.944098Z\",\"shell.execute_reply.started\":\"2024-05-05T00:46:20.930491Z\",\"shell.execute_reply\":\"2024-05-05T00:46:20.943206Z\"}}\n","def reduce_mem_usage(df):\n","    \"\"\" iterate through all the columns of a dataframe and modify the data type\n","        to reduce memory usage.\n","    \"\"\"\n","    start_mem = df.memory_usage().sum() / 1024**2\n","    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n","\n","    for col in df.columns:\n","        col_type = df[col].dtype\n","        if str(col_type)==\"category\":\n","            continue\n","\n","        if col_type != object:\n","            c_min = df[col].min()\n","            c_max = df[col].max()\n","            if str(col_type)[:3] == 'int':\n","                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n","                    df[col] = df[col].astype(np.int8)\n","                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n","                    df[col] = df[col].astype(np.int16)\n","                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n","                    df[col] = df[col].astype(np.int32)\n","                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n","                    df[col] = df[col].astype(np.int64)\n","            else:\n","                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n","                    df[col] = df[col].astype(np.float16)\n","                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n","                    df[col] = df[col].astype(np.float32)\n","                else:\n","                    df[col] = df[col].astype(np.float64)\n","        else:\n","            continue\n","    end_mem = df.memory_usage().sum() / 1024**2\n","    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n","    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n","\n","    return df\n","\n","# %% [markdown] {\"papermill\":{\"duration\":0.006776,\"end_time\":\"2024-02-10T04:58:34.934015\",\"exception\":false,\"start_time\":\"2024-02-10T04:58:34.927239\",\"status\":\"completed\"},\"tags\":[]}\n","# # Data collection\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-05T00:46:20.946731Z\",\"iopub.execute_input\":\"2024-05-05T00:46:20.947315Z\",\"iopub.status.idle\":\"2024-05-05T00:46:20.973026Z\",\"shell.execute_reply.started\":\"2024-05-05T00:46:20.947282Z\",\"shell.execute_reply\":\"2024-05-05T00:46:20.972161Z\"}}\n","class Pipeline:\n","    @staticmethod\n","    def set_table_dtypes(df):\n","        for col in df.columns:\n","            if col in [\"case_id\", \"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n","                df = df.with_columns(pl.col(col).cast(pl.Int32))\n","            elif col in [\"date_decision\"]:\n","                df = df.with_columns(pl.col(col).cast(pl.Date))\n","            elif col[-1] in (\"P\", \"A\"):\n","                df = df.with_columns(pl.col(col).cast(pl.Float64))\n","            elif col[-1] in (\"M\",):\n","                df = df.with_columns(pl.col(col).cast(pl.String))\n","            elif col[-1] in (\"D\",):\n","                df = df.with_columns(pl.col(col).cast(pl.Date))\n","\n","        return df\n","\n","    @staticmethod\n","    def handle_dates(df):\n","        for col in df.columns:\n","            if col[-1] in (\"D\",):\n","                df = df.with_columns(pl.col(col) - pl.col(\"date_decision\"))\n","                df = df.with_columns(pl.col(col).dt.total_days())\n","                df = df.with_columns(pl.col(col).cast(pl.Float32))\n","\n","        df = df.drop(\"date_decision\", \"MONTH\")\n","\n","        return df\n","\n","    @staticmethod\n","    def filter_cols(df):\n","        for col in df.columns:\n","            if col not in [\"target\", \"case_id\", \"WEEK_NUM\"]:\n","                isnull = df[col].is_null().mean()\n","\n","                # # TODO: Revisar el sentido de este filtro\n","                # if col[-1]=='M':\n","                #     specific_value_ratio = df.filter(pl.col(col) == \"a55475b1\").height / df.height\n","                #     if specific_value_ratio > 0.95:\n","                #         df = df.drop(col)\n","\n","                if isnull > 0.95:\n","                    df = df.drop(col)\n","\n","        for col in df.columns:\n","            if (col not in [\"target\", \"case_id\", \"WEEK_NUM\"]) & (df[col].dtype == pl.String):\n","                freq = df[col].n_unique()\n","\n","                if (freq == 1) | (freq > 50):\n","                    df = df.drop(col)\n","\n","            # # eliminate yaer, month feature\n","            # if (col[-1] not in [\"P\", \"A\", \"L\", \"M\"]) and (('month_' in col) or ('year_' in col)):\n","            #     df = df.drop(col)\n","\n","        # for col in cols_drop:\n","        #     if col in df.columns:\n","        #         df = df.drop(col)\n","\n","        return df\n","\n","\n","    # AÃ±adidos los 3 siguientes metodos\n","    @staticmethod\n","    def reduce_memory_usage_pl(df):\n","        \"\"\" Reduce memory usage by polars dataframe {df} with name {name} by changing its data types.\n","            Original pandas version of this function: https://www.kaggle.com/code/arjanso/reducing-dataframe-memory-size-by-65\n","        \"\"\"\n","        print(f\"Memory usage of dataframe is {round(df.estimated_size('mb'), 2)} MB\")\n","\n","        Numeric_Int_types = [pl.Int8, pl.Int16, pl.Int32, pl.Int64]\n","        Numeric_Float_types = [pl.Float32, pl.Float64]\n","\n","        for col in df.columns:\n","            if col == 'case_id':\n","                continue\n","            try:\n","                col_type = df[col].dtype\n","\n","                if col_type == pl.Categorical:\n","                    continue\n","\n","                c_min = df[col].min()\n","                c_max = df[col].max()\n","\n","                if col_type in Numeric_Int_types:\n","                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n","                        df = df.with_columns(df[col].cast(pl.Int8))\n","                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n","                        df = df.with_columns(df[col].cast(pl.Int16))\n","                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n","                        df = df.with_columns(df[col].cast(pl.Int32))\n","                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n","                        df = df.with_columns(df[col].cast(pl.Int64))\n","\n","                elif col_type in Numeric_Float_types:\n","                    if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n","                        df = df.with_columns(df[col].cast(pl.Float32))\n","                    else:\n","                        pass\n","                # elif col_type == pl.Utf8:\n","                #     df = df.with_columns(df[col].cast(pl.Categorical))\n","                else:\n","                    pass\n","            except:\n","                pass\n","        print(f\"Memory usage of dataframe became {round(df.estimated_size('mb'), 2)} MB\")\n","        return df\n","\n","    @staticmethod\n","    def fill_missing_values(df):\n","        num_cnt = 0\n","        cat_cnt = 0\n","        for col in df.columns:\n","            if df[col].dtype.is_numeric():\n","                df = df.with_columns(pl.col(col).fill_null(-1).alias(col))\n","                num_cnt += 1\n","            else:\n","                df = df.with_columns(pl.col(col).fill_null(\"Missing\").alias(col))\n","                cat_cnt += 1\n","        print(\"num_cnt : \", num_cnt)\n","        print(\"cat_cnt : \", cat_cnt)\n","        return df\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-05T00:46:20.974176Z\",\"iopub.execute_input\":\"2024-05-05T00:46:20.974509Z\",\"iopub.status.idle\":\"2024-05-05T00:46:20.990447Z\",\"shell.execute_reply.started\":\"2024-05-05T00:46:20.974478Z\",\"shell.execute_reply\":\"2024-05-05T00:46:20.989676Z\"}}\n","class Aggregator:\n","    @staticmethod\n","    def num_expr(df):\n","        cols = [col for col in df.columns if col[-1] in (\"P\", \"A\")]\n","\n","        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols] + [pl.min(col).alias(f\"min_{col}\") for col in cols] # + [pl.sum(col).alias(f\"sum_{col}\") for col in cols]\n","        # expr_diff = [pl.col(col).diff().alias(f\"diff_{col}\") for col in cols]\n","\n","        return expr_max + [pl.mean(col).alias(f\"mean_{col}\") for col in cols] + [pl.std(col).alias(f\"std_{col}\") for col in cols] # + expr_diff\n","\n","        # [pl.col(col).drop_nulls().last().alias(f\"last_{col}\") for col in cols]\n","\n","    @staticmethod\n","    def date_expr(df):\n","        cols = [col for col in df.columns if col[-1] in (\"D\",)]\n","\n","        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols] + [pl.min(col).alias(f\"min_{col}\") for col in cols] # + [pl.sum(col).alias(f\"sum_{col}\") for col in cols]\n","\n","        return expr_max # + [pl.mean(col).alias(f\"mean_{col}\") for col in cols]\n","\n","    @staticmethod\n","    def str_expr(df):\n","        cols = [col for col in df.columns if col[-1] in (\"M\",)]\n","\n","        expr_max = [pl.last(col).alias(f\"last_{col}\") for col in cols] + \\\n","            [pl.n_unique(col).alias(f\"n_unique_{col}\") for col in cols] + \\\n","            [pl.first(col).alias(f\"first_{col}\") for col in cols]  # High Value\n","\n","        return expr_max\n","\n","    @staticmethod\n","    def other_expr(df):\n","        cols = [col for col in df.columns if col[-1] in (\"T\", \"L\")]\n","\n","        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols] + [pl.min(col).alias(f\"min_{col}\") for col in cols] + [pl.sum(col).alias(f\"sum_{col}\") for col in cols]\n","\n","        return expr_max # + [pl.mean(col).alias(f\"mean_{col}\") for col in cols] + [pl.std(col).alias(f\"std_{col}\") for col in cols]\n","\n","    @staticmethod\n","    def count_expr(df):\n","        cols = [col for col in df.columns if \"num_group\" in col]\n","\n","        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols] # + [pl.n_unique(col).alias(f\"n_unique_{col}\") for col in cols]\n","\n","        return expr_max\n","\n","    @staticmethod\n","    def get_exprs(df):\n","        exprs = Aggregator.num_expr(df) + \\\n","                Aggregator.date_expr(df) + \\\n","                Aggregator.str_expr(df) + \\\n","                Aggregator.other_expr(df) + \\\n","                Aggregator.count_expr(df)\n","\n","        return exprs\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-05T00:46:20.991497Z\",\"iopub.execute_input\":\"2024-05-05T00:46:20.991771Z\",\"iopub.status.idle\":\"2024-05-05T00:46:21.007096Z\",\"shell.execute_reply.started\":\"2024-05-05T00:46:20.991749Z\",\"shell.execute_reply\":\"2024-05-05T00:46:21.006226Z\"}}\n","def read_file(path, depth=None):\n","    df = pl.read_parquet(path)\n","    df = df.pipe(Pipeline.set_table_dtypes)\n","\n","    if depth in [1]:\n","        df = df.sort(\"num_group1\").group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n","    elif depth in [2]:\n","        df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n","    df = df.pipe(Pipeline.reduce_memory_usage_pl)\n","    return df\n","\n","def read_files(regex_path, depth=None):\n","    chunks = []\n","    for path in glob(str(regex_path)):\n","        df = pl.read_parquet(path)\n","        df = df.pipe(Pipeline.set_table_dtypes)\n","\n","        if depth in [1]:\n","            df = df.sort(\"num_group1\").group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n","        elif depth in [2]:\n","            df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n","\n","        chunks.append(df)\n","\n","    df = pl.concat(chunks, how=\"vertical_relaxed\")\n","    df = df.unique(subset=[\"case_id\"])\n","\n","    df = df.pipe(Pipeline.reduce_memory_usage_pl)\n","\n","    return df\n","\n","def feature_eng(df_base, depth_0, depth_1, depth_2, is_train=True):\n","    df_base = (\n","        df_base\n","        .with_columns(\n","            decision_month = pl.col(\"date_decision\").dt.month(),\n","            decision_weekday = pl.col(\"date_decision\").dt.weekday(),\n","        )\n","    )\n","\n","    for i, df in enumerate(depth_0 + depth_1 + depth_2):\n","        df_base = df_base.join(df, how=\"left\", on=\"case_id\", suffix=f\"_{i}\")\n","\n","    df_base = df_base.pipe(Pipeline.handle_dates)\n","    if is_train:\n","        df_base = df_base.pipe(Pipeline.filter_cols)\n","    df_base = df_base.pipe(Pipeline.fill_missing_values)\n","\n","    return df_base\n","\n","def to_pandas(df_data, cat_cols=None):\n","    df_data = df_data.to_pandas()\n","\n","    if cat_cols is None:\n","        cat_cols = list(df_data.select_dtypes(\"object\").columns)\n","\n","    df_data[cat_cols] = df_data[cat_cols].astype(\"category\")\n","\n","    return df_data, cat_cols\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-05T00:46:21.008131Z\",\"iopub.execute_input\":\"2024-05-05T00:46:21.008411Z\",\"iopub.status.idle\":\"2024-05-05T00:46:21.020794Z\",\"shell.execute_reply.started\":\"2024-05-05T00:46:21.008389Z\",\"shell.execute_reply\":\"2024-05-05T00:46:21.019975Z\"}}\n","from pathlib import Path\n","from glob import glob\n","\n","ROOT            = Path(\"/kaggle/input/home-credit-credit-risk-model-stability\")\n","TRAIN_DIR       = ROOT / \"parquet_files\" / \"train\"\n","TEST_DIR        = ROOT / \"parquet_files\" / \"test\"\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-05T00:46:21.021879Z\",\"iopub.execute_input\":\"2024-05-05T00:46:21.022207Z\",\"iopub.status.idle\":\"2024-05-05T00:46:21.553731Z\",\"shell.execute_reply.started\":\"2024-05-05T00:46:21.022158Z\",\"shell.execute_reply\":\"2024-05-05T00:46:21.552792Z\"}}\n","data_store = {\n","    \"df_base\": read_file(TEST_DIR / \"test_base.parquet\"),\n","    \"depth_0\": [\n","        read_file(TEST_DIR / \"test_static_cb_0.parquet\"),\n","        read_files(TEST_DIR / \"test_static_0_*.parquet\"),\n","    ],\n","    \"depth_1\": [\n","        read_files(TEST_DIR / \"test_applprev_1_*.parquet\", 1),\n","        read_file(TEST_DIR / \"test_tax_registry_a_1.parquet\", 1),\n","        read_file(TEST_DIR / \"test_tax_registry_b_1.parquet\", 1),\n","        read_file(TEST_DIR / \"test_tax_registry_c_1.parquet\", 1),\n","        read_files(TEST_DIR / \"test_credit_bureau_a_1_*.parquet\", 1),\n","        read_file(TEST_DIR / \"test_credit_bureau_b_1.parquet\", 1),\n","        read_file(TEST_DIR / \"test_other_1.parquet\", 1),\n","        read_file(TEST_DIR / \"test_person_1.parquet\", 1),\n","        read_file(TEST_DIR / \"test_deposit_1.parquet\", 1),\n","        read_file(TEST_DIR / \"test_debitcard_1.parquet\", 1),\n","    ],\n","    \"depth_2\": [\n","        read_file(TEST_DIR / \"test_credit_bureau_b_2.parquet\", 2),\n","        read_files(TEST_DIR / \"test_credit_bureau_a_2_*.parquet\", 2),\n","        read_file(TEST_DIR / \"test_applprev_2.parquet\", 2),\n","        read_file(TEST_DIR / \"test_person_2.parquet\", 2)\n","    ]\n","}\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-05T00:46:21.554798Z\",\"iopub.execute_input\":\"2024-05-05T00:46:21.555088Z\",\"iopub.status.idle\":\"2024-05-05T00:46:22.189875Z\",\"shell.execute_reply.started\":\"2024-05-05T00:46:21.555063Z\",\"shell.execute_reply\":\"2024-05-05T00:46:22.189053Z\"}}\n","df_test = feature_eng(**data_store, is_train=False)\n","print(\"test data shape:\\t\", df_test.shape)\n","del data_store\n","gc.collect()\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-05T00:46:22.192593Z\",\"iopub.execute_input\":\"2024-05-05T00:46:22.192868Z\",\"iopub.status.idle\":\"2024-05-05T00:46:22.744567Z\",\"shell.execute_reply.started\":\"2024-05-05T00:46:22.192845Z\",\"shell.execute_reply\":\"2024-05-05T00:46:22.743676Z\"}}\n","# df_test = df_test.select([col for col in df_train.columns if col != \"target\"])\n","df_test = df_test.select(['case_id', 'WEEK_NUM'] + cat_features)\n","# print(\"train data shape:\\t\", df_train.shape)\n","print(\"test data shape:\\t\", df_test.shape)\n","\n","df_test, cat_cols = to_pandas(df_test, cat_cols)\n","# df_test = reduce_mem_usage(df_test)\n","\n","gc.collect()\n","\n","# %% [markdown] {\"papermill\":{\"duration\":0.031773,\"end_time\":\"2024-02-10T05:23:03.16254\",\"exception\":false,\"start_time\":\"2024-02-10T05:23:03.130767\",\"status\":\"completed\"},\"tags\":[]}\n","# # Prediction\n","\n","# %% [code] {\"execution\":{\"iopub.status.busy\":\"2024-05-05T00:46:22.745798Z\",\"iopub.execute_input\":\"2024-05-05T00:46:22.746081Z\",\"iopub.status.idle\":\"2024-05-05T00:46:22.751998Z\",\"shell.execute_reply.started\":\"2024-05-05T00:46:22.746057Z\",\"shell.execute_reply\":\"2024-05-05T00:46:22.751168Z\"}}\n","def cat_prediction(feats, models):\n","    predictions = np.zeros(len(feats))\n","    for model in models:\n","        p = model.predict_proba(feats)[:, 1]\n","        predictions += p/len(models)\n","    return predictions\n","\n","# %% [code] {\"papermill\":{\"duration\":0.041537,\"end_time\":\"2024-02-10T05:23:03.235674\",\"exception\":false,\"start_time\":\"2024-02-10T05:23:03.194137\",\"status\":\"completed\"},\"tags\":[],\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-05T00:46:22.753123Z\",\"iopub.execute_input\":\"2024-05-05T00:46:22.753499Z\",\"iopub.status.idle\":\"2024-05-05T00:46:22.762590Z\",\"shell.execute_reply.started\":\"2024-05-05T00:46:22.753468Z\",\"shell.execute_reply\":\"2024-05-05T00:46:22.761734Z\"}}\n","def predict_proba_in_batches(models, data, batch_size=200000): # about 35min per 10k\n","    num_samples = len(data)\n","    num_batches = int(np.ceil(num_samples / batch_size))\n","    probabilities = np.zeros((num_samples,))\n","\n","    for batch_idx in range(num_batches):\n","        print(f\"Processing batch: {batch_idx+1}/{num_batches}\")\n","        start_idx = batch_idx * batch_size\n","        end_idx = min((batch_idx + 1) * batch_size, num_samples)\n","\n","        X_batch = data.iloc[start_idx:end_idx]\n","\n","        # batch_probs = joblib.load(f'{automl_path}denselight_model.pkl').predict(X_batch).data.squeeze()\n","        batch_probs = cat_prediction(X_batch, models)\n","\n","        probabilities[start_idx:end_idx] = batch_probs\n","\n","        del X_batch\n","        gc.collect()\n","\n","    return probabilities\n","\n","# %% [code] {\"papermill\":{\"duration\":0.706127,\"end_time\":\"2024-02-10T05:23:03.973644\",\"exception\":false,\"start_time\":\"2024-02-10T05:23:03.267517\",\"status\":\"completed\"},\"tags\":[],\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-05T00:46:22.763684Z\",\"iopub.execute_input\":\"2024-05-05T00:46:22.763949Z\",\"iopub.status.idle\":\"2024-05-05T00:46:23.107455Z\",\"shell.execute_reply.started\":\"2024-05-05T00:46:22.763926Z\",\"shell.execute_reply\":\"2024-05-05T00:46:23.106464Z\"}}\n","X_test = df_test.drop(columns=[\"WEEK_NUM\"])\n","X_test = X_test.set_index(\"case_id\")\n","print(\"X_test shape: \", df_test.shape)\n","\n","y_pred = pd.Series(predict_proba_in_batches(models, X_test), index=X_test.index)\n","y_pred[:10]\n","\n","# %% [markdown] {\"papermill\":{\"duration\":0.032096,\"end_time\":\"2024-02-10T05:23:04.038858\",\"exception\":false,\"start_time\":\"2024-02-10T05:23:04.006762\",\"status\":\"completed\"},\"tags\":[]}\n","# # Submission\n","\n","# %% [code] {\"papermill\":{\"duration\":0.053299,\"end_time\":\"2024-02-10T05:23:04.124231\",\"exception\":false,\"start_time\":\"2024-02-10T05:23:04.070932\",\"status\":\"completed\"},\"tags\":[],\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-05T00:46:23.108784Z\",\"iopub.execute_input\":\"2024-05-05T00:46:23.109127Z\",\"iopub.status.idle\":\"2024-05-05T00:46:23.119589Z\",\"shell.execute_reply.started\":\"2024-05-05T00:46:23.109089Z\",\"shell.execute_reply\":\"2024-05-05T00:46:23.118715Z\"}}\n","subm_df = pd.read_csv(\"/kaggle/input/home-credit-credit-risk-model-stability/sample_submission.csv\")\n","subm_df = subm_df.set_index(\"case_id\")\n","subm_df[\"score\"] = y_pred\n","\n","# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-05T00:46:23.120667Z\",\"iopub.execute_input\":\"2024-05-05T00:46:23.120911Z\",\"iopub.status.idle\":\"2024-05-05T00:46:23.128696Z\",\"shell.execute_reply.started\":\"2024-05-05T00:46:23.120890Z\",\"shell.execute_reply\":\"2024-05-05T00:46:23.127794Z\"}}\n","print(subm_df)\n","\n","# %% [code] {\"papermill\":{\"duration\":0.043978,\"end_time\":\"2024-02-10T05:23:04.283155\",\"exception\":false,\"start_time\":\"2024-02-10T05:23:04.239177\",\"status\":\"completed\"},\"tags\":[],\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2024-05-05T00:46:23.129850Z\",\"iopub.execute_input\":\"2024-05-05T00:46:23.130275Z\",\"iopub.status.idle\":\"2024-05-05T00:46:23.139601Z\",\"shell.execute_reply.started\":\"2024-05-05T00:46:23.130244Z\",\"shell.execute_reply\":\"2024-05-05T00:46:23.138759Z\"}}\n","subm_df.to_csv(\"submission.csv\")"]}]}